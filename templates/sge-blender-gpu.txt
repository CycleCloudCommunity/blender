######################################
## SGE with Blender Batch Rendering ##
######################################

[parameters About]
Order = 1

    [[parameters About Blender]]

        [[[parameter Blender]]]
        HideLabel = true
        Config.Plugin = pico.widget.HtmlTemplateWidget
        Config.Template := "<table><tr><td><img src='https://s3.amazonaws.com/download.cyclecomputing.com/logos/blender-socket-192x60.png' width='192' height='60'></td></tr><tr><td><p>This cluster installs Blender alongside SGE for Batch Rendering.</p><br><p>Blender is the free and open source 3D creation suite. It supports the entirety of the 3D pipelineâ€”modeling, rigging, animation, simulation, rendering, compositing and motion tracking, even video editing and game creation.</p><br><p>See the <a href=\"https://www.blender.org/\" target=\"_blank\">Blender project site</a> for an overview.</p></td></tr></table>"


[parameters General Settings]
Order = 5

    [[parameters Cloud Service Provider Configuration]]
    Description = Configure the Cloud Provider account options.
    Order = 10

   [[[parameter CloudProvider]]]
   Label = Cloud Provider
   ParameterType = Cloud.Provider
	DefaultValue = azure
	Hidden = true

   [[[parameter Credentials]]]
   Description = The credentials for the cloud provider
   ParameterType = Cloud.Credentials

   [[[parameter Region]]]
   Label = Region
   Description = Deployment Location
   ParameterType = Cloud.Region
	DefaultValue = westus2

   [[[parameter KeyPairLocation]]]
   Label = Keypair Path
   Description = The path to the private SSH key to use for the `cyclecloud` user on the nodes.
   DefaultValue = /opt/cycle_server/.ssh/cyclecloud.pem
   Required = True

[parameters Filesystem Configuration]
Description = "Select the Persistent Filesystem"
Order = 10

	[[parameter FileSystemClusterName]]
	Label = Filesystem Cluster
	Description = The filesystem to mount
	Config.Plugin = pico.form.QueryDropdown
	Config.Query = select ClusterName as Name from Cloud.Node join Cloud.Cluster CC on ClusterName === CC.ClusterName where CC.IsTemplate =!= True && Configuration.role=?="sharedfs"
	Config.SetDefault = false
	Config.Required = true
	
	[[parameter MountPoint]]
	Label = Mount Point
	Description = The path at which to mount the Filesystem
	DefaultValue = /data

	[[parameter ExportPath]]
	Label = Export Path
	Description = The path exported by the file system
	DefaultValue = /mnt/exports/avere

[parameters Cluster Software]
Order = 20
    
    [[parameters Software]]
    Description = Specify the base OS and optional cluster-init spec(s) from your locker.
    Order = 10


        [[[parameter ClusterUserName]]]
        Label = Default User
        DefaultValue = cluster.user
        Hidden = true

        [[[parameter ClusterUserPubKey]]]
        Label = Default User Pub. Key
        Hidden = true

        [[[parameter DefaultClusterInitSpecs]]]
        Label = Default Specs
        Description = Cluster init specs to apply to all nodes
        ParameterType = Cloud.ClusterInitSpecs

        [[[parameter MasterSpecs]]]
        Label = Cluster-Init
        DefaultValue = =undefined
        Description = Cluster init specs to apply to the master node
        ParameterType = Cloud.ClusterInitSpecs
    
        [[[parameter ExecuteSpecs]]]
        Label = Cluster-Init
        DefaultValue = =undefined
        Description = Cluster init specs to apply to execute nodes
        ParameterType = Cloud.ClusterInitSpecs
    
[parameters Compute Backend]
Order = 30

    [[parameters Nodes]]
    Order = 10
    
        [[[parameter MachineType]]]
        Label = Machine Type
        Description = The machine type for all nodes
        Config.Plugin = pico.form.QueryDropdown
        Config.Query := "select Name as Label, [Name=Name; GPUCount=GPUCount] as Value from Cloud.MachineType where GPU == True && Provider == ${CloudProvider}"
        Config.Parameters := { "CloudProvider" }
        Config.SetDefault = true
        Config.Required = true

    [[parameters Auto-Scaling]]
    Description = "The cluster can autoscale to the workload, adding execute hosts as jobs are queued. To enable this check the box below and choose the initial and maximum core counts for the cluster"
    Order = 20

        [[[parameter Autoscale]]]
        Label = Autoscale
        DefaultValue = true
        Widget.Plugin = pico.form.BooleanCheckBox
        Widget.Label = Start and stop execute nodes automatically

        [[[parameter InitialExecuteCoreCount]]]
        Label = Initial Cores
        Description = The number of execute cores to launch on startup
        DefaultValue = 0
        Config.Plugin = pico.form.NumberTextBox
        Config.MinValue = 0
        Config.MaxValue = 5000
        Config.IntegerOnly = true

        [[[parameter MaxExecuteCoreCount]]]
        Label = Max Cores
        Description = The total number of execute cores to start
        DefaultValue = 10
        Config.Plugin = pico.form.NumberTextBox
        Config.MinValue = 1
        Config.MaxValue = 5000
        Config.IntegerOnly = true

    [[parameters Azure Low Priority]]
    Description = "To use low priority instances check the box, otherwise on-demand instances will be used"
    Conditions.Excluded := CloudProvider !== "Azure"
    Order = 30

        [[[parameter azureUseLowPrio]]]
        Label = Use Low Prio Instances
        DefaultValue = false
        Widget.Plugin = pico.form.BooleanCheckBox
        Widget.Label = Use low priority instances for execute hosts

        [[[parameter azureBatchAccount]]]
        Label = Azure Batch Account
        Conditions.Excluded := azureUseLowPrio isnt true        


[parameters Networking]
Order = 40
    
    [[parameters General]]
    Order = 10

        [[[parameter ReturnProxy]]]
        Label = Return Proxy
        DefaultValue = true
        ParameterType = Boolean
        Config.Label = Use SSH tunnel to connect to CycleCloud (required if direct access is blocked)

        [[[parameter MasterPublicIp]]]
        Label = Master has Public IP
        DefaultValue = true
        Widget.Plugin = pico.form.BooleanCheckBox
        Widget.Label = Assign a public ip address to the master node
    
        [[[parameter SubnetId]]]
        Label = Subnet ID
        Description = Subnet Resource Path (ResourceGroup/VirtualNetwork/Subnet)
        Conditions.Required := CloudProvider === "Azure"
        Conditions.Excluded := CloudProvider !== "Azure"
        ParameterType = Azure.Subnet


[cluster sge-blender]
FormLayout = selectionpanel
IconUrl = https://s3.amazonaws.com/download.cyclecomputing.com/logos/blender-192x170.png
Category = Animation and Rendering

# Enable/disable autoscaling
# The scheduler load will determine the number of execute machines that are started, machines will terminate themselves if they are idle
# and approaching a billing cycle.
Autoscale = $Autoscale

    # defines default values used for all nodes. This is inherited automatically by all nodes.
    # You can create other nodes like this by adding Abstract = true to them and adding
    # Extends = foo to the nodes that should inherit the definitions from foo.
    [[node defaults]]
    Credentials = $Credentials
    MachineType = ${MachineType.Name}
    ImageName = cycle.image.ubuntu16
    SubnetId = $SubnetId
    Region = $Region
    KeyPairLocation = $keypairLocation
    AdditionalClusterInitSpecs = $DefaultClusterInitSpecs
    
        [[[configuration]]]
        # You can specify Chef attributes using dot notation if needed. For example, you
        # can use it to change the default CycleServer admin password (defaults to cluster name):
        cyclecloud.cluster.user.name = $ClusterUserName
        cyclecloud.cluster.user.uid = 55555
        cyclecloud.cluster.user.gid = 55555
        cyclecloud.cluster.user.public_key = $ClusterUserPubKey

        [[[configuration blender]]]
        version = 2.79b-linux-glibc219
        
        [[[configuration nvidia]]]
        # Currently, 384.111 is currently the latest version supported with the Meltdown patches
        # - Since we're overriding the driver version, don't install the driver from the CUDA package
        driver.build = 384.111
        cuda.install_driver = false
        cuda.version = 8.0
        cuda.build = 8.0.61_375.26_linux
        cudnn.version = 6.0

        [[[configuration cyclecloud.mounts.nfs]]]
        type = nfs
        export_path = $ExportPath
        mountpoint = $MountPoint
        cluster_name = $FilesystemClusterName

        [[[network-interface eth0]]]
        AssociatePublicIpAddress = false

        [[[cluster-init nvidia:driver:1.1.0]]]
        [[[cluster-init blender:default:1.0.0]]]

    [[node master]]
    IsReturnProxy = $ReturnProxy
    AdditionalClusterInitSpecs = $MasterSpecs

        [[[configuration]]]
        # This is the Chef runlist to use for the node, to customize this add customized recipes and/or roles
        # Example: run_list=role[sge_master_role], role[monitor], recipe[mysql::server]
        run_list = role[sge_master_role]        

        [[[configuration nvidia]]]
        # IMPORTANT: cuda profile generation is for driver-only nodes (it will fail on the cuda host)
        cuda.disable_profile = true

        # Configure Azure external input endpoints (for example SSH)
        [[[input-endpoint SSH]]]
        PrivatePort = 22
        PublicPort = 22

        [[[input-endpoint ganglia]]]
        PrivatePort = 8652
        PublicPort = 8652        

        [[[network-interface eth0]]]
        AssociatePublicIpAddress = $MasterPublicIp

        [[[cluster-init nvidia:cuda:1.1.0]]]
        [[[cluster-init nvidia:sge:1.1.0]]]


    [[nodearray execute]]
    AdditionalClusterInitSpecs = $ExecuteSpecs

    # The initial number of cores of this type to start when the cluster starts
    InitialCoreCount= $InitialExecuteCoreCount

    # The maximum number of cores to start when the cluster is configured for autoscaling
    MaxCoreCount = $MaxExecuteCoreCount

    CoreCount = ${MachineType.GPUCount}

    # Azure Low Priority Instances?
    BatchAccount = $azureBatchAccount
    Interruptible = $azureUseLowPrio


        [[[configuration]]]
        run_list = role[sge_execute_role]

        # OPTIONAL: cluster will also use a Consumable Resource to ensure that only GPUCount gpu jobs
        #           run per node.   Without this setting, regular CPU jobs will be allowed to fill the
        #           node's remaining CPUs.  With this setting, the node will ONLY be used for GPU jobs.
        gridengine.slots = ${MachineType.GPUCount}

        [[[cluster-init nvidia:sge:1.1.0]]]


